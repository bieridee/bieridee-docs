\documentclass[10pt,a4paper]{scrartcl}
\pagestyle{empty}
\usepackage{a4} % alternativ \usepackage{a4wide}
\usepackage[ngerman]{babel} % Neudeutsche Silbentrennung (mehrsprachiges Dokument)
\usepackage{parskip} % Skip indentation of first row
\usepackage{graphicx} % Graphics support
\usepackage{longtable} % Tables across several pages
\usepackage{booktabs}
\usepackage{hyperref} % Hyperlinks
\usepackage[automark]{scrpage2} %kopf/fusszeile
\usepackage[utf8x]{inputenc} % Unicode-Encoding
 
\linespread{1.3}

\author{Danilo Bargen, Christian Fässler, Jonas Furrer} 
\title{Qualitätsmanagement\\ Projekt BierIdee}

\pagestyle{scrheadings}
\ihead{SE2 Projekte} %linke Kopfzeile
\ohead{BierIdee} %rechte Kopfzeile

\begin{document}

\begin{titlepage}
	\maketitle
	\vspace{120mm}
	\thispagestyle{empty} % Don't start page numbers on this page
\end{titlepage}

\tableofcontents
\newpage

\section*{Änderungshistorie}
\begin{tabular}{p{0.1\textwidth}p{0.15\textwidth}p{0.55\textwidth}p{0.1\textwidth}}
\toprule
\textbf{Version} & \textbf{Datum} & \textbf{Änderung} & \textbf{Person} \\  
\midrule
v1.0 & 30.05.2012 & Dokument erstellt & dbargen \\  
\bottomrule
\end{tabular} 
\newpage


\section{Einführung}

\subsection{Zweck}
Dieses Dokument beschreibt die Qualitätssicherungsmassnahmen des Projektes BierIdee.

\subsection{Gültigkeitsbereich}
Die Gültigkeit des Dokumentes beschränkt sich auf die Dauer des SE2-Projekte Modules FS2012.

\subsection{Referenzen}

\begin{itemize}
	\item Definition.of.Done.pdf
	\item usertest.baumann.pdf
	\item usertest.tanner.pdf
\end{itemize}


\section{Definition of Done}

Als primäre Qualitätssicherungsmassnahme wurde eine Definition of Done\footnote{Siehe
\textit{Definition.of.Done.pdf}} erstellt. Diese enthält folgende Qualitätsrelevanten Punkte:

\subsection{Code Reviews}

Um die Qualität unserer Codebasis zu gewährleisten, wurden regelmässig Code Reviews
durchgeführt. Gemäss Steve McConnell \cite{mcconnell2005code} ist dies eine äusserst effektive
Qualitätsmassnahme:

\begin{quote}
	\ldots{} software testing alone has limited effectiveness -- the average defect detection rate is only 25
	percent for unit testing, 35 percent for function testing, and 45 percent for integration testing.
	In contrast, the average effectiveness of design and code inspections are 55 and 60 percent. Case
	studies of review results have been impressive \ldots
\end{quote}

Gemäss der Definition of Done darf kein nichttrivialer Code in den \texttt{main} Branch gemerged
werden, ohne dass er reviewed wurde.

\subsection{Code-Kommentare}

Um die Codebasis übersichtlich und gut verständlich zu halten, sollten überall wo sinnvoll
Code-Kommentare eingefügt werden. Klassen und Methoden müssen mit Javadoc kommentiert werden. Daraus
wird nach Abschluss des Projektes eine Javadoc-HTML-Hilfe generiert.

\subsection{Checkstyle}

Wir haben während dem Projekt Checkstyle\footnote{\url{http://checkstyle.sourceforge.net/}}
eingesetzt und dafür unsere eigene Konfiguration erstellt. Um die Definition of Done zu erfüllen,
dürfen im Code mithilfe unserer Checkstyle-Konfiguration keine Warnungen mehr vorhanden sein.

\subsection{Unit Tests}

Unit Tests müssen vorhanden sein, um die neu erstellte Funktionalität zu testen. Im Backend wurde
dafür JUnit 4 eingesetzt, im Frontend JUnit 3 mit
Robotium\footnote{\url{http://code.google.com/p/robotium/}}.

\subsection{Continuous Integration}

Damit die Codebasis stets kompilierbar bleibt, wurde ein Jenkins Buildserver eingesetzt. Dieser
wurde mit diversen Plugins erweitert (GitHub Plugin, Maven Plugin, Android Plugin, etc\ldots). Neben
dem Buildvorgang wurden auch die Unit- und Integrationtests ausgeführt.

Zu Beginn des Projektes wurde vereinbart, dass ein durch Unachtsamkeit verschuldeter Build Fail
bestraft wird -- die entsprechende Person muss am nächsten Tag Gipfeli für das Team mitbringen.

Die Continuous Integration verlief leider nicht so reibungslos wie erwartet. Durch Probleme mit dem
Caching der Codebasis (das Repository wurde nicht jedesmal neu ausgecheckt sondern nur updated) war
der Build-Status auf dem Integrationsserver häufig auf "`Fehlerhaft"', obwohl der Build wie auch
alle Tests eigentlich erfolgreich durchführbar waren. Diese Probleme wurden jeweils durch ein
manuelles "`cleaning"' des Workspace gelöst.

\section{Issue Tracking}

Um den Überblick über die geplanten Tasks zu behalten und um sicherzustellen, dass keine Features
vergessen gehen, wurde während dem Projekt konsequent mit Redmine gearbeitet. Alle Aufgaben wurden
in Tasks unterteilt und den jeweiligen Personen zugeteilt. Zeitschätzungen wurden eingetragen und
Kategorien gesetzt.

\section{Usertests}

Um auch Feedback von Benutzern zu erhalten und so auf Probleme aufmerksam zu werden die man als
Entwickler häufig übersieht, haben wir ein Testprotokoll erstellt und die App von Freiwilligen
testen lassen. Die Erkenntnisse flossen jeweils direkt in den Entwicklungszyklus ein.

Zwei Beispiele sind in in den PDF-Dateien \texttt{usertest.\-baumann.\-pdf} und
\texttt{usertest.\-tanner.\-pdf} beigefügt.

\section{Protokolle}

Für jedes Meeting wurde jeweils ein Protokoll erstellt. Zu Beginn haben wir dafür die Website
http://minutes.io/ verwendet, später sind wir wegen Bugs in ihrem System davon weggekommen und haben
die Protokolle in Textdateien erstellt.


\bibliographystyle{alpha}
\bibliography{QA}


\end{document}
